{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Lab3-exercise.ipynb","version":"0.3.2","provenance":[{"file_id":"167YBWPpBLpRLzAPvbR26dh5-HsmAvDPt","timestamp":1553758006778}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"h5s6lx2A67pO","colab_type":"code","colab":{}},"cell_type":"code","source":["# # Verify GPU\n","# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","# !pip install gputil\n","# !pip install psutil\n","# !pip install humanize\n","# import psutil\n","# import humanize\n","# import os\n","# import GPUtil as GPU\n","# GPUs = GPU.getGPUs()\n","# # XXX: only one GPU on Colab and isnâ€™t guaranteed\n","# gpu = GPUs[0]\n","# def printm():\n","#   process = psutil.Process(os.getpid())\n","#   print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n","#   print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","# printm()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XSX-ZziB67on","colab_type":"text"},"cell_type":"markdown","source":["## Import used python libraries"]},{"metadata":{"id":"JSRsp1XjgjXL","colab_type":"code","colab":{}},"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/gdrive/')\n","# %cd gdrive/My\\ Drive/Nvidia/Lab3"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CqZUULEq67oo","colab_type":"code","outputId":"23f97961-446a-4320-95c0-72e4e1a61857","executionInfo":{"status":"ok","timestamp":1547052947960,"user_tz":-420,"elapsed":4837,"user":{"displayName":"Amarin Jettakul","photoUrl":"","userId":"09960094437448966795"}},"colab":{"base_uri":"https://localhost:8080/","height":90}},"cell_type":"code","source":["# Downgrade Pillow to avoid errors\n","!pip install Pillow==3.4.2\n","\n","import tensorflow as tf\n","from keras.applications.vgg19 import VGG19, preprocess_input\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.pooling import MaxPooling2D\n","from keras.models import Model\n","from keras import optimizers \n","from keras import regularizers\n","from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n","from time import time\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","np.random.seed(12)\n","\n","from sklearn.metrics import classification_report, f1_score, accuracy_score\n","import glob\n","from tqdm import tqdm\n","import warnings\n","\n","import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n","shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n","The folder you are executing pip from can no longer be found.\n"],"name":"stdout"}]},{"metadata":{"id":"dl2WNFMy67o4","colab_type":"text"},"cell_type":"markdown","source":["## Variable path Setting\n","- training, validation, testing and model path directories."]},{"metadata":{"id":"-YxiD0dM67o5","colab_type":"code","colab":{}},"cell_type":"code","source":["train_dir = \"./dataset/lab3-1/7_flower/train\"\n","val_dir = \"./dataset/lab3-1/7_flower/validate\"\n","test_dir = \"./dataset/lab3-1/7_flower/test\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ma711SoX67o9","colab_type":"text"},"cell_type":"markdown","source":["## Data preprocessing\n","\n","Read training and validation dataset\n","- Data augmentation strategies using ImageDataGenerator"]},{"metadata":{"id":"wt2OtHP867o_","colab_type":"code","outputId":"a2b42a81-8c94-4dfa-dd66-5078297d10de","executionInfo":{"status":"error","timestamp":1547052724419,"user_tz":-420,"elapsed":2467,"user":{"displayName":"Amarin Jettakul","photoUrl":"","userId":"09960094437448966795"}},"colab":{"base_uri":"https://localhost:8080/","height":507}},"cell_type":"code","source":["image_size = 224\n","num_class = 7\n","\n","batch_size=32\n","\n","train_datagen = ImageDataGenerator(\n","        preprocessing_function=preprocess_input,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True)\n"," \n","validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","train_generator = train_datagen.flow_from_directory(\n","        train_dir,\n","        target_size=(224, 224),\n","        batch_size=batch_size,\n","        class_mode='categorical')\n"," \n","validation_generator = validation_datagen.flow_from_directory(\n","        val_dir,\n","        target_size=(224,224),\n","        batch_size=batch_size,\n","        class_mode='categorical')"],"execution_count":0,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-cc068a731628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         class_mode='categorical')\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m validation_generator = validation_datagen.flow_from_directory(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m             interpolation=interpolation)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m     def flow_from_dataframe(self, dataframe, directory,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1875\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1876\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset/lab3-1/7_flower/train'"]}]},{"metadata":{"id":"6-sfZkad67pO","colab_type":"text"},"cell_type":"markdown","source":["## `To do`\n","\n","You are supposed to implement your own model using any techniques with the provided flower dataset with 7 classes as can described below.\n","    - Training dataset contains 336 images.\n","    - Validation dataset contains 112 images.\n","    - Testing dataset contains 112 images.\n","And you can measure the model performance by F1-score evaluator which its codes are also provided in the cell below."]},{"metadata":{"id":"n8Im0OCW67pP","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"M7qVkDMH67pV","colab_type":"text"},"cell_type":"markdown","source":["## Evaluation"]},{"metadata":{"id":"8AvqP80167pX","colab_type":"code","colab":{}},"cell_type":"code","source":["class_to_idx = train_generator.class_indices\n","idx_to_class = {v: k for k, v in class_to_idx.items()}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-PY4pRZI67pa","colab_type":"code","colab":{}},"cell_type":"code","source":["y_trues = []\n","y_preds = []\n","        \n","for class_idx in tqdm(range(num_class)):\n","    label = idx_to_class[class_idx]\n","    file_list = glob.glob(\"{}/{}/*.jpg\".format(test_dir, label))\n","    for raw_image in file_list:\n","        inputShape = (224,224)\n","        image = load_img(raw_image, target_size=inputShape)\n","        image = img_to_array(image)\n","        image = preprocess_input(image)\n","        image = np.expand_dims(image, axis=0)\n","        \n","        # Change `model` to be your model varaible here\n","        preds = model.predict(image)\n","        pred_class = np.argmax(preds)\n","\n","        y_trues.append(class_idx)\n","        y_preds.append(pred_class)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GZYVwlAu67pe","colab_type":"code","colab":{}},"cell_type":"code","source":["with warnings.catch_warnings():\n","    warnings.simplefilter(\"ignore\")\n","    print(\"-- Performace Model: (acc:{:.4f}, f1_micro:{:.4f}, f1_macro:{:.4f})\".format(accuracy_score(y_trues, y_preds), \n","                                                                                f1_score(y_trues, y_preds, average='micro'),\n","                                                                                f1_score(y_trues, y_preds, average='macro')))\n"],"execution_count":0,"outputs":[]}]}